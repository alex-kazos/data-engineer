{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb807a5",
   "metadata": {},
   "source": [
    "# Data Pipelines: Exercise Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e410a",
   "metadata": {},
   "source": [
    "## 1. Write ETL Functions\n",
    "- Write Python functions for extract, transform, and load steps for a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "    import pandas as pd\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def transform(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def load(df, path):\n",
    "    df.to_csv(path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a00b1",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Modularize Pipeline\n",
    "- Refactor your ETL code to use functions and pass data between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9fe651",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Add Logging\n",
    "- Add logging to each step of your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "def extract(path):\n",
    "    logging.info(f'Extracting from {path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07026e7c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Schedule with Airflow (optional)\n",
    "- Create a simple Airflow DAG that runs your ETL pipeline daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8b026",
   "metadata": {},
   "source": [
    "## 5. Error Handling\n",
    "- Add error handling and retries to your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = extract('input.csv')\n",
    "except Exception as e:\n",
    "    logging.error(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b5b33",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Challenge\n",
    "- Add a configuration file (YAML/JSON) for pipeline parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f3395",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "# config.yaml\n",
    "input: 'input.csv'\n",
    "output: 'output.csv'\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
